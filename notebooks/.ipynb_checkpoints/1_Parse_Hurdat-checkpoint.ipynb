{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import folium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_hurdat(url, local_fname, location):\n",
    "    if not os.path.exists(local_fname):\n",
    "        urlretrieve(url, local_fname)\n",
    "\n",
    "    records = []\n",
    "    with open(local_fname,'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(location):\n",
    "                record = line.strip()\n",
    "                reports = []\n",
    "                records.append((record, reports))\n",
    "            else:\n",
    "                reports.append(line.strip())\n",
    "                \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.nhc.noaa.gov/data/hurdat/hurdat2-1851-2017-050118.txt\"\n",
    "local_fname = \"../data/hurdat2.txt\"\n",
    "\n",
    "records = read_hurdat(url, local_fname, \"AL\") # AL for atlantic hurricanes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Parse data into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_hurricanes(records):\n",
    "    \"\"\"\n",
    "    The raw records from hurdat2 is a list of lists. We want \n",
    "    to parse this into a neat dataframe for easy analysis.\n",
    "    \"\"\"\n",
    "    hurr_list = []\n",
    "    for hurricane in tqdm(records, total=len(records)):\n",
    "        year = hurricane[0].split(',')[0][-4:]\n",
    "        hurr_id = hurricane[0].split(',')[0]\n",
    "        hurr_list.append(hurr_id)\n",
    "            \n",
    "    num_hurr = len(hurr_list)\n",
    "    records_for_yr = records[-num_hurr:]\n",
    "    \n",
    "    return records_for_yr\n",
    "\n",
    "def create_hurricane_df(records):\n",
    "    \"\"\"\n",
    "    The raw data from NOAA is a text file. This function parses that\n",
    "    text file into a nice, readable Pandas dataframe for easy manipulation.\n",
    "    \"\"\"\n",
    "    records_df = pd.DataFrame()\n",
    "    idx = 0\n",
    "\n",
    "    for record in records:\n",
    "        hurricane_id = record[0].split(',')[0]\n",
    "        hurricane_name = record[0].split(',')[1].strip()\n",
    "\n",
    "        for datapoint in record[1]:\n",
    "            data_list = [x.strip() for x in datapoint.split(',')]\n",
    "            record_date = data_list[0]\n",
    "            time = data_list[1]\n",
    "            storm_status = data_list[3]\n",
    "            lat = data_list[4]\n",
    "            lon = data_list[5]\n",
    "            max_wind = data_list[6]\n",
    "            min_pressure = data_list[7]\n",
    "\n",
    "            # Add to df\n",
    "            records_df.loc[idx, 'id'] = hurricane_id\n",
    "            records_df.loc[idx, 'name'] = hurricane_name\n",
    "            records_df.loc[idx, 'date'] = record_date\n",
    "            records_df.loc[idx, 'time'] = time\n",
    "            records_df.loc[idx, 'dt'] = datetime.datetime.strptime(record_date+time,'%Y%m%d%H%M')        \n",
    "            records_df.loc[idx, 'storm_status'] = storm_status\n",
    "            records_df.loc[idx, 'lat'] = convert_lat_lon(lat, 'lat')\n",
    "            records_df.loc[idx, 'lon'] = convert_lat_lon(lon, 'lon')\n",
    "            records_df.loc[idx, 'max_wind'] = float(max_wind)\n",
    "            records_df.loc[idx, 'min_pressure'] = float(min_pressure)\n",
    "\n",
    "            idx +=1\n",
    "            \n",
    "    return records_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_records = get_all_hurricanes(records)\n",
    "hurricanes_df_raw = create_hurricane_df(all_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Functions to identify individual storms\n",
    "\n",
    "Feature engineering for:\n",
    "* If hurricane was over land at each time interval\n",
    "* If hurricane ever made landfall \n",
    "* Duration of the hurricane\n",
    "* If the storm reached hurricane status|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_category(input_df):\n",
    "    \"\"\"\n",
    "    Each row is a hurricane at a point in time. Category will vary\n",
    "    depending on wind speed at the time. We want to have an identifier\n",
    "    for what each hurricane's max recorded category was.\n",
    "    \"\"\"\n",
    "    df = input_df.copy(deep=True)\n",
    "    for hurricane in df['id'].unique():\n",
    "        hurr_df = df[df['id']==hurricane]\n",
    "        try:\n",
    "            max_cat = max(hurr_df[hurr_df['category']!='TS']['category'])\n",
    "        except ValueError:\n",
    "            max_cat = 'TS'\n",
    "        df_indexes = hurr_df.index\n",
    "        df.loc[df_indexes, 'category_highest'] = max_cat\n",
    "        \n",
    "    return df\n",
    "\n",
    "def over_land(hurricane_df):\n",
    "    bm = Basemap()\n",
    "    hurricane_df['over_land'] = np.nan\n",
    "\n",
    "    for i, row in hurricane_df.iterrows():\n",
    "        hurricane_df.loc[i, 'over_land'] = np.where(bm.is_land(hurricane_df.loc[i, 'lat'], \n",
    "                                                                hurricane_df.loc[i, 'lon'])==True, \n",
    "                                                     1, 0)\n",
    "        \n",
    "    return hurricane_df\n",
    "\n",
    "def made_landfall(storm_df):\n",
    "    storm_df['landfall'] = np.nan # initialize\n",
    "    storm_df['landfall'] = np.where(storm_df['over_land'].sum()>0, 1, 0)\n",
    "    \n",
    "    return storm_df\n",
    "\n",
    "def storm_duration(storm_df):\n",
    "    storm_df['duration'] = np.nan # initialize\n",
    "    start = storm_df['dt'].min()\n",
    "    end = storm_df['dt'].max()\n",
    "    storm_df['duration'] = end - start\n",
    "    \n",
    "    return storm_df\n",
    "\n",
    "def is_hurricane(storm_df):\n",
    "    storm_df['is_hurricane'] = np.nan\n",
    "    storm_df['is_hurricane'] = np.where(storm_df['storm_status'].any()==\"HU\", 1, 0)\n",
    "    \n",
    "    return storm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine if hurricane was over land for each data point\n",
    "all_hurricanes_df = over_land(hurricanes_df_raw)\n",
    "\n",
    "# Get storm-specific data\n",
    "hurricanes_cleaned = []\n",
    "for storm_id in all_hurricanes_df['id'].unique():\n",
    "    storm_df = all_hurricanes_df[all_hurricanes_df['id']==storm_id]\n",
    "    \n",
    "    # Did it make landfall?\n",
    "    made_landfall(storm_df)\n",
    "    # How long was it?\n",
    "    storm_duration(storm_df)\n",
    "    # Did it reach hurricane status?\n",
    "    is_hurricane(storm_df)\n",
    "    \n",
    "    hurricanes_cleaned.append(storm_df)\n",
    "\n",
    "all_hurricanes_df_cleaned = pd.concat(hurricanes_cleaned)\n",
    "\n",
    "# Add year\n",
    "all_hurricanes_df_cleaned['year'] = pd.DatetimeIndex(all_hurricanes_df_cleaned['dt']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hurricanes_df_cleaned.to_csv('../data/hurricanes_df_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
